{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmNFpN4lVrHFM/wMS+Fp/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Corassini/Curso_deep_learning/blob/main/Exercicio_selecao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abrindo o Arquivo CISI"
      ],
      "metadata": {
        "id": "V0cGQobEP7pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf cisi.tar.gz"
      ],
      "metadata": {
        "id": "_ZZBEf_lPhOx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ49lZlzQYFZ",
        "outputId": "a44b877d-c550-4edd-afb6-c94f60fe1bf2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTYdMB-SP2ag",
        "outputId": "6007a567-fffc-415c-f3d2-2c6286eb514a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CISI.ALL  CISI.BLN  CISI.QRY  CISI.REL\tcisi.tar.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lendo os arquivos CISI e separando em diferentes variáveis"
      ],
      "metadata": {
        "id": "kw_drAT8R8rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer() \n",
        "tokenizer = RegexpTokenizer(r'\\w+')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p6K-E-cbWJ8",
        "outputId": "0fead0da-64dd-4d15-dc35-ff97b882a183"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/CISI.ALL','r') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "\n",
        "doc_set = {}\n",
        "doc_id = \"\"\n",
        "doc_text = \"\"\n",
        "\n",
        "for l in lines:\n",
        "    if l.startswith(\".I\"):\n",
        "        doc_id = l.split(\" \")[1].strip() \n",
        "    elif l.startswith(\".X\"):\n",
        "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
        "        doc_id = \"\"\n",
        "        doc_text = \"\"\n",
        "    else:\n",
        "        doc_text += l.strip()[3:] + \" \" \n",
        "\n",
        "documents = []\n",
        "for key, value in doc_set.items():\n",
        "  documents.append(value)\n",
        "doc_token = []\n",
        "for item in documents:\n",
        "  doc_token.append([stemmer.stem(token) for token in tokenizer.tokenize(item.lower()) if token not in stop_words])"
      ],
      "metadata": {
        "id": "ISEYMHJ_3rcN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/CISI.QRY', 'r') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "      \n",
        "qry_set = {}\n",
        "qry_id = \"\"\n",
        "for l in lines:\n",
        "    if l.startswith(\".I\"):\n",
        "        qry_id = l.split(\" \")[1].strip() \n",
        "    elif l.startswith(\".W\"):\n",
        "        qry_set[qry_id] = l.strip()[3:]\n",
        "        qry_id = \"\"\n",
        "\n",
        "\n",
        "queries = []\n",
        "for key, value in qry_set.items():\n",
        "  queries.append(value)\n",
        "queries_token = []\n",
        "for item in queries:\n",
        "  queries_token.append([stemmer.stem(token) for token in tokenizer.tokenize(item.lower()) if token not in stop_words])"
      ],
      "metadata": {
        "id": "iAzZarF7QZlO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel_set = {}\n",
        "with open('/content/CISI.REL', 'r') as f:\n",
        "    for l in f.readlines():\n",
        "        qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0] \n",
        "        doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1]\n",
        "\n",
        "        if qry_id in rel_set:\n",
        "            rel_set[qry_id].append(doc_id)\n",
        "        else:\n",
        "            rel_set[qry_id] = []\n",
        "            rel_set[qry_id].append(doc_id)\n",
        "\n",
        "print(f\"\\n\\nNumber of mappings = {len(rel_set)}\")\n",
        "print(rel_set[\"1\"]) "
      ],
      "metadata": {
        "id": "jU5thiDfSwSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e549859a-9412-4cfa-df28-56beabf6d710"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Number of mappings = 76\n",
            "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementando o BM25"
      ],
      "metadata": {
        "id": "RcQGgBFRYfen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.summarization.bm25 import BM25\n",
        "from gensim.summarization.bm25 import get_bm25_weights"
      ],
      "metadata": {
        "id": "1WL_lSK4YfT5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bm25 = BM25(doc_token)"
      ],
      "metadata": {
        "id": "PTJhh7dMYeXG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculando o IDF médio\n",
        "idf_values = model_bm25.idf.values()\n",
        "idf_sum = 0\n",
        "for value in idf_values:\n",
        "  idf_sum += value\n",
        "idf_mean = idf_sum / len(idf_values)"
      ],
      "metadata": {
        "id": "P__kjKZgddUa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculando o score\n",
        "scores = []\n",
        "for query in queries_token:\n",
        "  query_scores = model_bm25.get_scores(query,idf_mean)\n",
        "  scores.append(query_scores)"
      ],
      "metadata": {
        "id": "EFu64QWLYoFV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, query in enumerate(queries_token):\n",
        "    ranked_documents = sorted(range(len(scores[i])), key=lambda j: scores[i][j], reverse=True)\n",
        "    print(\"Consulta: \", query)\n",
        "    print(\"Documentos mais relevantes: \", [k+1 for k in ranked_documents[:]])"
      ],
      "metadata": {
        "id": "T-yQEvgydjkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculando a acurácia"
      ],
      "metadata": {
        "id": "wtDjCp2AdSDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rel_set = {}\n",
        "with open('/content/CISI.REL', 'r') as f:\n",
        "    for l in f.readlines():\n",
        "        qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0] \n",
        "        doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1]\n",
        "\n",
        "        if qry_id in rel_set:\n",
        "            rel_set[qry_id].append(doc_id)\n",
        "        else:\n",
        "            rel_set[qry_id] = []\n",
        "            rel_set[qry_id].append(doc_id)"
      ],
      "metadata": {
        "id": "nUE1FaaMqRsb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_return = []\n",
        "model_return.append('')\n",
        "ground_truth = []\n",
        "ground_truth.append('')\n",
        "\n",
        "for i, query in enumerate(queries_token):\n",
        "  ranked_documents = sorted(range(len(scores[i])), key=lambda j: scores[i][j], reverse=True)\n",
        "  if str(i+1) in rel_set:\n",
        "    model_return.append([k+1 for k in ranked_documents[:len(rel_set[str(i+1)])]])\n",
        "    ground_truth.append([int(k) for k in rel_set[str(i+1)]])\n",
        "  else:\n",
        "    model_return.append([])\n",
        "    ground_truth.append([])"
      ],
      "metadata": {
        "id": "46qP3ixPTQr5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_list = []\n",
        "for i in range(1,len(queries)+1):\n",
        "  acerto =0\n",
        "  for k in model_return[i]:\n",
        "    if k in ground_truth[i]:\n",
        "      acerto += 1\n",
        "  if ground_truth[i] != []:\n",
        "    precision_list.append(acerto/len(ground_truth[i]))\n",
        "  else:\n",
        "    precision_list.append(-9)\n",
        "\n",
        "precision_final =0\n",
        "count = 0\n",
        "for i in range(len(precision_list)):\n",
        "  if precision_list[i] != -9:\n",
        "    precision_final +=precision_list[i]\n",
        "    count +=1\n",
        "\n",
        "precision_final_2 = precision_final/count\n",
        "print(precision_final_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvkw1VigUueb",
        "outputId": "b823afbf-5e32-48e4-ddb7-bc2dfa31cff6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2498303025107418\n"
          ]
        }
      ]
    }
  ]
}