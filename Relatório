Relatório

Para a recuperação de informações (IR) que é o que o exercicio se propõe, foi feita a sugestão de utilizar duas arquiteturas: BM25 e GPT-3.
Tentando entende-las mais a fundo, o BM25 é de fato uma boa escolha para o exercício. Mas, o GPT-3 por se tratar de um modelo de gerar textos, respoder perguntas como de fato é o ChatGPT, esse tipo de arquitetura não seria a melhor escolha para IR
Logo, o exercício desenvolvido no Google Colab foi somente utilizando o BM25 para a recuperação de informação. E utilizado o ChatGPT para eventuais dúvidas que surgiriam, assim utilizando o modelo GPT-3.
Para utilização da CISI collection, foi pesquisado o que cada arquivo dentro do zip signficaria. E, portanto foi utilizando somente 3 arquivos.
O .ALL que tem todos os resumos - logo o corpus
O .QRY que tem as buscas por resumos
O .REL que seria a devolutiva das buscas relativas a cada resumo.
Todos os 3 arquivos foram necessários ser tratados. Sempre deixando as palavras em uma lista, removendo stopwords e reduzindo elas ao seu radical.Usando a biblioteca NLTK.
Remover stop words ajuda em relação ao não utilizar stopwords ("what", "is", "that"...) para a recuperação de informações. Ou seja, se uma pesquisa (.QRY) utiliza muito a palavra "what" o modelo iria pegar o resumo que mais tem a palavra "what" não sendo necessariamente do mesmo assunto. Por isso a remoção desses tipos de palavras para ajudar na busca e deixa-la mais assertiva.
Também utilzado o stemmer que seria para reduzir as palavras ao seu radical, assim diminuindo a quantiade de palavras que há no vocabulário (implicito à biblioteca Gensim) e ao calculo de IDF, logo assim palavras semelhantes não seriam tratadas como palavras raras.
Depois desses tratamentos acima descritos, foi pesquisado no chatGPT como utilizaria o modelo BM25. E foi sugerido uma biblioteca Gensim ("from gensim.summarization.bm25 import BM25"). Nessa biblioteca se torna mais fácil a implementação do modelo, pois os cálculos de IR são abstraídos do código.
Logo, apenas um comando: "model_bm25 = BM25(corpus)" já faz todos os calculos, deixando assim o modelo já treinado para o input das pesquisas.
Também foi necessário calcular o IDF, como mencionado acima, que faz o calculo da raridade das palavras que apareceram no corpus. Sendo assim mais fácil de ligar o corpus às consultas que tem a mesma palavra (ou radical da palavra).
Dessa maneira foi feita o ranqueamento dos artigos relacionados à cada pesquisa. Logo, para cada pesquisa teríamos a mesma quantidade de documentos, mas ordenados de maneira distinta, seguindo o score de probabilidade daquele documento pertencer àquela pesquisa.
Portanto, para calcular a assertividade do modelo ser tornaria um pouco mais complicado, pois a relação de artigos/documentos relacionados a cada busca tem uma quantidade variável.
Logo, adotei que cada busca deveria de retornar a mesma quantidade de documentos que o arquivo .REL para assim facilitar sua comparação e o calculo de assertividade.
Mas, não necessariamente seria a melhor maneira de tratar isso. Poderia limitar em 10 documentos por pesquisa, ou qualquer outro número; poderia também faer um corte (mediana) no score e trazer somente os documentos que estão acima desse score. Essas maneiras dificultariam um pouco o calculo pois nem sempre o denominador da razão entre acerto e quantidade de documentos seria o mesmo. Portanto, foi decidido seguir pelo calculo exposto da primeira maneira.
Existem também consultas que não deveriam de retornar nenhum documento, tamém houve esse tratamento no calculo da assertividade do modelo. Atribuindo o valor de -9 para a consulta que não existe. Assim, quando foi calculado a assertividade foi deconsiderado esses casos.
Dessa maneira, a assertividade/precisão do modelo ficou por volta de 24%. Particulamente o número não foi próximo do que era esperado, mas devido às consultas no chatGPT e até mesmo no documento de implementação do Gensim não foi encontrada outra maneira de conseguir melhorar esse número de assertividade.
Ficando assim como proximos passos: utilizar maneiras diferentes de medir a assertividade/acurácia do modelo, e consutar possíveis melhorias nos parametros do modelo para melhorar a acurácia.
